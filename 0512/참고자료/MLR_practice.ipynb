{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 다중 회귀 분석 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬에서 Multiple Linear Regression을 실행하기 위해 scikit-learn 패키지를 사용\n",
    "보통은 데이터를 외부에서 읽어들여 전처리 후 모델링을 진행하지만, 기존의 scikit-learn에 샘플데이터셋이 있으므로 이를 이용하여 실습을 진행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이썬에서 패키지를 사용하기 위해서는 'import' 함수를 사용하며,\n",
    "만약에 패키지 중 일부만을 사용하고자 할 때는 'from package import subpackage'를 진행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 패키지 import 및 데이터 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 셋의 형태를 파악하기 위해 데이터를 출력해본다. 데이터셋의 형태는 딕셔너리 형태로, key가 data와 target으로 구분되어있다. 친절하게 scikit-learn에서는 데이터를 미리 전처리해두어서 data(X, 독립변수), target(Y, 종속변수)로 구분지어놨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[ 0.03807591,  0.05068012,  0.06169621, ..., -0.00259226,\n",
      "         0.01990842, -0.01764613],\n",
      "       [-0.00188202, -0.04464164, -0.05147406, ..., -0.03949338,\n",
      "        -0.06832974, -0.09220405],\n",
      "       [ 0.08529891,  0.05068012,  0.04445121, ..., -0.00259226,\n",
      "         0.00286377, -0.02593034],\n",
      "       ...,\n",
      "       [ 0.04170844,  0.05068012, -0.01590626, ..., -0.01107952,\n",
      "        -0.04687948,  0.01549073],\n",
      "       [-0.04547248, -0.04464164,  0.03906215, ...,  0.02655962,\n",
      "         0.04452837, -0.02593034],\n",
      "       [-0.04547248, -0.04464164, -0.0730303 , ..., -0.03949338,\n",
      "        -0.00421986,  0.00306441]]), 'target': array([151.,  75., 141., 206., 135.,  97., 138.,  63., 110., 310., 101.,\n",
      "        69., 179., 185., 118., 171., 166., 144.,  97., 168.,  68.,  49.,\n",
      "        68., 245., 184., 202., 137.,  85., 131., 283., 129.,  59., 341.,\n",
      "        87.,  65., 102., 265., 276., 252.,  90., 100.,  55.,  61.,  92.,\n",
      "       259.,  53., 190., 142.,  75., 142., 155., 225.,  59., 104., 182.,\n",
      "       128.,  52.,  37., 170., 170.,  61., 144.,  52., 128.,  71., 163.,\n",
      "       150.,  97., 160., 178.,  48., 270., 202., 111.,  85.,  42., 170.,\n",
      "       200., 252., 113., 143.,  51.,  52., 210.,  65., 141.,  55., 134.,\n",
      "        42., 111.,  98., 164.,  48.,  96.,  90., 162., 150., 279.,  92.,\n",
      "        83., 128., 102., 302., 198.,  95.,  53., 134., 144., 232.,  81.,\n",
      "       104.,  59., 246., 297., 258., 229., 275., 281., 179., 200., 200.,\n",
      "       173., 180.,  84., 121., 161.,  99., 109., 115., 268., 274., 158.,\n",
      "       107.,  83., 103., 272.,  85., 280., 336., 281., 118., 317., 235.,\n",
      "        60., 174., 259., 178., 128.,  96., 126., 288.,  88., 292.,  71.,\n",
      "       197., 186.,  25.,  84.,  96., 195.,  53., 217., 172., 131., 214.,\n",
      "        59.,  70., 220., 268., 152.,  47.,  74., 295., 101., 151., 127.,\n",
      "       237., 225.,  81., 151., 107.,  64., 138., 185., 265., 101., 137.,\n",
      "       143., 141.,  79., 292., 178.,  91., 116.,  86., 122.,  72., 129.,\n",
      "       142.,  90., 158.,  39., 196., 222., 277.,  99., 196., 202., 155.,\n",
      "        77., 191.,  70.,  73.,  49.,  65., 263., 248., 296., 214., 185.,\n",
      "        78.,  93., 252., 150.,  77., 208.,  77., 108., 160.,  53., 220.,\n",
      "       154., 259.,  90., 246., 124.,  67.,  72., 257., 262., 275., 177.,\n",
      "        71.,  47., 187., 125.,  78.,  51., 258., 215., 303., 243.,  91.,\n",
      "       150., 310., 153., 346.,  63.,  89.,  50.,  39., 103., 308., 116.,\n",
      "       145.,  74.,  45., 115., 264.,  87., 202., 127., 182., 241.,  66.,\n",
      "        94., 283.,  64., 102., 200., 265.,  94., 230., 181., 156., 233.,\n",
      "        60., 219.,  80.,  68., 332., 248.,  84., 200.,  55.,  85.,  89.,\n",
      "        31., 129.,  83., 275.,  65., 198., 236., 253., 124.,  44., 172.,\n",
      "       114., 142., 109., 180., 144., 163., 147.,  97., 220., 190., 109.,\n",
      "       191., 122., 230., 242., 248., 249., 192., 131., 237.,  78., 135.,\n",
      "       244., 199., 270., 164.,  72.,  96., 306.,  91., 214.,  95., 216.,\n",
      "       263., 178., 113., 200., 139., 139.,  88., 148.,  88., 243.,  71.,\n",
      "        77., 109., 272.,  60.,  54., 221.,  90., 311., 281., 182., 321.,\n",
      "        58., 262., 206., 233., 242., 123., 167.,  63., 197.,  71., 168.,\n",
      "       140., 217., 121., 235., 245.,  40.,  52., 104., 132.,  88.,  69.,\n",
      "       219.,  72., 201., 110.,  51., 277.,  63., 118.,  69., 273., 258.,\n",
      "        43., 198., 242., 232., 175.,  93., 168., 275., 293., 281.,  72.,\n",
      "       140., 189., 181., 209., 136., 261., 113., 131., 174., 257.,  55.,\n",
      "        84.,  42., 146., 212., 233.,  91., 111., 152., 120.,  67., 310.,\n",
      "        94., 183.,  66., 173.,  72.,  49.,  64.,  48., 178., 104., 132.,\n",
      "       220.,  57.]), 'DESCR': '.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - Age\\n      - Sex\\n      - Body mass index\\n      - Average blood pressure\\n      - S1\\n      - S2\\n      - S3\\n      - S4\\n      - S5\\n      - S6\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttp://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(http://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)', 'feature_names': ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6'], 'data_filename': 'E:\\\\SW\\\\anaconda3\\\\envs\\\\bigdatatest\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\diabetes_data.csv.gz', 'target_filename': 'E:\\\\SW\\\\anaconda3\\\\envs\\\\bigdatatest\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\diabetes_target.csv.gz'}\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력받은 데이터를 X,Y로 구분하여 처리한다. x 데이터의 형태를 확인하기 위해 아래와 같이 진행한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n"
     ]
    }
   ],
   "source": [
    "x = data['data']\n",
    "y = data['target']\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 분할은 scikit-learn에서 제공하는 train_test_split을 이용하면 편리하다. 아래와 같이 split을 하게되면 하나의 데이터로 부터 특정 비율만큼을 트레이닝셋으로, 나머지를 테스트셋으로 구분하여 활용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((309, 10), (133, 10), (309,), (133,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size=0.3, random_state=0)\n",
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn에서의 모델 트레이닝은 매우 간단한데, 아래와 같이 특정 모델의 객체를 생성 한 후, 각 객체에 공통적으로 존재하는 fit함수를 사용하면 주어진 데이터에 대해서 학습을 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr = LinearRegression()\n",
    "mlr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLR 모델에서 추정한 회귀변수를 보고자 한다면 아래와 같이 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [ -52.46990775 -193.51064552  579.4827762   272.46404234 -504.72401371\n",
      "  241.68441866  -69.73618783   86.62018451  721.95580222   26.77887028]\n"
     ]
    }
   ],
   "source": [
    "# The coefficients\n",
    "print('Coefficients: \\n', mlr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델의 적합성을 확인하기 위해 수업시간에 배운 R-square를 구해보자.\n",
    "여러가지 metric은 scikit-learn에서 사용할 수 있도록 모듈로 구성되어 있으므로, 이를 import하여 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3928939845074757\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "pred = mlr.predict(X_test)\n",
    "print(r2_score(Y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추가 패키지 사용 - statsmodels 패키지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "statsmodels 패키지에서는 OLS 클래스를 이용하여 선형회귀분석을 실시한다. 아래와 같이 패키지를 입력하고, OLS 모형을 이용하여 회귀분석을 실시한다. scikit-learn과의 차이점은 아래와 같다. \n",
    "- 모델 객체 생성시 미리 데이터를 입력해줘야한다. \n",
    "- 자동으로 상수항을 만들지 않기 때문에 'add_constant'를 이용하여 상수항을 추가해줘야 한다. \n",
    "\n",
    "아래는 결과 summary를 확인하기 위해 상수항은 따로 추가하지 않고 실행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.regression.linear_model import OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       0.106\n",
      "Model:                            OLS   Adj. R-squared:                  0.076\n",
      "Method:                 Least Squares   F-statistic:                     3.554\n",
      "Date:                Thu, 11 Jul 2019   Prob (F-statistic):           0.000183\n",
      "Time:                        15:30:28   Log-Likelihood:                -2010.9\n",
      "No. Observations:                 309   AIC:                             4042.\n",
      "Df Residuals:                     299   BIC:                             4079.\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1           -94.5943    217.856     -0.434      0.664    -523.320     334.131\n",
      "x2          -108.8227    220.067     -0.494      0.621    -541.900     324.254\n",
      "x3           529.9252    243.543      2.176      0.030      50.650    1009.200\n",
      "x4           326.7419    248.223      1.316      0.189    -161.743     815.227\n",
      "x5           181.5677   1485.137      0.122      0.903   -2741.078    3104.213\n",
      "x6          -511.8037   1187.478     -0.431      0.667   -2848.677    1825.070\n",
      "x7           -78.8246    776.199     -0.102      0.919   -1606.330    1448.681\n",
      "x8           465.0394    589.797      0.788      0.431    -695.641    1625.719\n",
      "x9           340.0635    601.944      0.565      0.573    -844.521    1524.648\n",
      "x10          -20.6244    232.680     -0.089      0.929    -478.522     437.273\n",
      "==============================================================================\n",
      "Omnibus:                        5.785   Durbin-Watson:                   0.208\n",
      "Prob(Omnibus):                  0.055   Jarque-Bera (JB):                3.806\n",
      "Skew:                           0.097   Prob(JB):                        0.149\n",
      "Kurtosis:                       2.492   Cond. No.                         22.1\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "model = OLS(Y_train, X_train)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn과 마찬가지로 predict라는 함수를 이용하여 예측을 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 79.35604986  90.20826117   8.09194496 -36.97148582  40.24065968\n",
      "  88.24090122 -42.21828014  26.93912291  -3.99031491  79.26578643\n",
      "   8.2648895   28.48101225 -46.80830476 -66.51983831  88.4234783\n",
      " -45.93179422 -10.8218498  -68.13614387 -55.33360783  47.461923\n",
      "  38.16214497  -4.5447892    6.56759019  -9.10295676  58.2610926\n",
      "   2.44262802 -22.35918837 -74.64330428  30.18044001  10.748149\n",
      "  24.66705442 -64.19173096 -10.9361286   -8.20704161 -23.74519905\n",
      "  28.69400992   1.50861315  46.43380411 -34.79575511  38.32607847\n",
      " -72.34149797  11.16568701 -22.7465025    9.7993116   34.16128536\n",
      " -78.18008196 -10.48608231 -16.6095517  -31.83365014  62.23435859\n",
      "   4.93659208 -65.05210695   1.37184048   1.70874549  70.35080937\n",
      "  43.81915436  34.92214274 -31.87574756 -31.74464622  10.93511267\n",
      "  47.87088619   9.0239927    0.59877324 -45.74400118  94.6854663\n",
      "  -7.20058459 -79.07213661  73.78038015  68.60076022 -88.73578827\n",
      " -71.87549218 -25.36093416 -44.83850007 -15.26730723 -16.2479792\n",
      "  50.09895398 -55.94612877  44.62869315  62.54302854  27.75235629\n",
      "  -8.88028452  55.47367057 -80.74248702  46.81380337 -66.94577287\n",
      " -68.37900508  -5.49905377  49.89159367 -21.86680658 -12.72993503\n",
      " -53.61499906 -23.51338426 -59.9059962  -10.54899284 -26.81793916\n",
      " -49.3573559   82.79223444  56.75191182 -24.89594367   0.1588696\n",
      "  33.72171333 -37.03547454  77.67186109 -74.36158673  65.67226753\n",
      " -35.85773468  66.85070689 117.06324578 -37.38898189 -36.58097882\n",
      "  32.27233503 -43.78171002  46.41042447 -44.83724316 -47.99016597\n",
      "  49.20657232  80.95721025 -51.10201985 132.44363029 -33.26166038\n",
      " -29.18903229 -44.32110009 -66.87065004  75.9592981  -51.28596016\n",
      " -25.29532132  55.21707192  18.64295283  29.46981755  12.62524624\n",
      "  44.0392782  -41.28672788  15.66646905]\n"
     ]
    }
   ],
   "source": [
    "pred = result.predict(X_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIF 구하기(feat. statsmodels 패키지)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIF를 구하기 위해서는 scikit-learn에서는 계산할 수 있는 모듈을 제공하고 있지 않다. 그러므로 다른 모듈을 사용하거나, 직접 계산하는 수 밖에 없다. 다행히, statsmodels 패키지에서 variance_inflation_factor로 제공하고있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "variance_inflation_factor함수는 첫번째 input으로 데이터셋 전체를 받고, 두번째 input으로 vif를 계산할 특정 변수의 index를 입력받는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vif = pd.DataFrame()\n",
    "vif['VIF Factor'] = [variance_inflation_factor(X_train, i) for i in range(X_train.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VIF Factor\n",
      "0    1.258764\n",
      "1    1.249004\n",
      "2    1.573517\n",
      "3    1.591749\n",
      "4   56.286046\n",
      "5   36.309338\n",
      "6   15.924893\n",
      "7    9.460528\n",
      "8    9.930956\n",
      "9    1.603518\n"
     ]
    }
   ],
   "source": [
    "print(vif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
